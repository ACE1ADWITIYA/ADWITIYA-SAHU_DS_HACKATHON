class TranscriptDataset:
    def __init__(self,path):
        with path.open("r",encoding="utf-8") as f :
            raw=json.load(f)
        self.data=raw["transcripts"]
        
    def flatten_turns(self,target_event="Escalation"):
        texts=[]
        labels=[]
        meta=[]
        for convo in self.data:
            label=1 if target_event.lower() in convo["intent"].lower() else 0
            for i,turn in enumerate(convo["conversation"]):
                texts.append(turn["text"])
                labels.append(label)
                meta.append({
                     "transcript_id":convo["transcript_id"],
                     # "time":t.get("time_of_interaction"),
                    # "domain":t.get("domain"),
                    "intent":convo.get("intent"),
                    "turn_index":i,
                    "speaker":turn["speaker"],
                    # "text":turn["text"]
                })
        return texts,np.array(labels),meta
class Embedder:
    def __init__ (self):
        self.model=SentenceTransformer("all-MiniLM-L6,v2")
    def encode(self,texts):
        return self.model.encode(texts,show_progress_bar=False)
        
class CausalModel:
    def __init__(self):
        self.clf=LogisticRegression(max_iter=2000)
    def train(self,X,y):
        self.clf.fit(X,y)
    def score(self,X):
        return self.clf.predict_proba(X)[:,1]
        
def extract_evidence(scores,meta,dataset,top_k=8):
    ranked=np.argsort(scores)[::-1][:top_k]
    evidence=[]
    for idx in ranked:
        m=meta[idx]
        convo=next(c for c in dataset.data if c["transcript_id"] == m["transcript_id"])
        turn=convo["conversation"][m["turn_index"]]
        evidence.append({
             "transcript_id":m["transcript_id"],
            # "time":t.get("time_of_interaction"),
            # "domain":t.get("domain"),
            "intent":m.get("intent"),
            # "turn_index":i,
            "speaker":m["speaker"],
            "text":turn["text"],
            "causal_score": float(scores[idx])
        })
    return evidence

def generate_explanation(event,evidence):
    explanation={
        "event":event,
        "causal_patterns":[],
        "evidence":evidence
    }
    
    for e in evidence:
        txt=e["text"].lower()
        if "supervisor" in txt or "manager" in txt:
            pattern="Escalation request pattern"
        elif "failed" in txt or "not working" in txt:
            pattern="Service failure repetition"
        elif "angry" in txt or "frustrated" in txt:
            pattern= "Customer emotional escalation"
        else:
            pattern="High-risk conversational trigger"
        explanation["causal_patterns"].append(pattern)
    return explanation


class contextmemory:
    def __init__(self):
        self.store={}
    def save(self,key,value):
        self.store[key]=value
    def load(self,key):
        return self.store.get(key)

class queryengine:
    def __init__(self,dataset,embedder,model,memory):
        self.dataset=dataset
        self.embedder=embedder
        self.model=model
        self.memory=memory
    def handlequery(self,query):
        q=query.lower()
        if "escalation in q":
            texts,labels,meta=self.dataset.flattern_turn()
            embeddings=self.embedder.encode(texts)
            scores=self.model.score(embeddings)
            evidence=extract_evidence(scores,meta,self.dataset)
            explanation=generate_explanation("Escalation",evidence)
            self.memory.save("last explanation",explanation)
            return explanation

        if "previous" in q or "evidence" in q:
            return self.memory.load("last_explanation")
        return {"message":"query not understood"}
def main():
    dataset=TranscriptDataset("Conversational_Transcript_Dataset.json")
    texts,labels,meta= dataset.flatten_turn()
    embedder=Embedder()
    embeddings=embedder.encode(texts)
    model=CausalModel()
    model.train(embeddings,labels)
    memory=contextmemory()
    engine=queryengine(dataset,embedder,model,memory)
    print("QUERY 1")
    result=engine.handlequery("why do escalation happen")
    print(result)
    print("follow")
    result2=engine.handlequery("show previous evidence")
    print(result2)

if __name__ == "main":
    main()
